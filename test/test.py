# 1. í•˜ë‚˜ì˜ ë°ì´í„°ì…‹ dataset[i]ê°€ 4ë§Œ í† í° ì´ë‚´ì¸ì§€ ì²´í¬
# 2. target audioì— ì˜ë¯¸ ì—†ëŠ” 1ì´ˆ ì´í•˜ ì˜¤ë””ì˜¤ê°€ ìˆëŠ”ì§€ ì²´í¬ (ë„ˆë¬´ ì§§ì€ ì˜¤ë””ì˜¤, ë¬¸ì¥ ë“±)
# 3. user ìƒ˜í”Œë§ 16000Hz, assistant ìƒ˜í”Œë§ 24000Hz ì²´í¬
# 4. ì „ì²´ êµ¬ì¡°ê°€ ì˜ë„í•œëŒ€ë¡œ ë‚˜ì™”ëŠ”ì§€ ì²´í¬ 
# 5. speaker_embeddingì´ ì œëŒ€ë¡œ ìˆëŠ”ì§€, ì‹¤íŒ¨í•´ì„œ 0ìœ¼ë¡œ ì±„ì›Œì§€ì§€ ì•Šì•˜ëŠ”ì§€ 
# 6. ì‹œìŠ¤í…œí”„ë¡¬í”„íŠ¸ ìˆëŠ”ì§€ , ì‹œí€€ìŠ¤ êµ¬ì¡°ê°€ ë§ëŠ”ì§€ 4 2 4 2 4 2 .. 
#7 . target_audio ëŠ” ì–´ë–»ê²Œ ì €ì¥ë˜ì–´ìˆëŠ”ì§€ í™•ì¸ 

#!/usr/bin/env -S uv run python
#!/usr/bin/env -S uv run python

import numpy as np
from pathlib import Path
from tqdm import tqdm
import textwrap
DEFAULT_INPUT_DIR = Path("./Multi-stream Spontaneous Conversation Training Dataset")

# [Import]
try:
    from src.sca_data.dataset_utils import easy_load, DuplexConfig, AudioSeg, Audio
except ImportError:
    from sca_data.dataset_utils import easy_load, DuplexConfig, AudioSeg, Audio
NUM_SAMPLES_TO_CHECK = 100  # <--- ì—¬ê¸°ë¥¼ ìˆ˜ì •í•˜ì„¸ìš”! (ì˜ˆ: 100ê°œë§Œ í™•ì¸)
def print_separator(title):
    print(f"\n{'='*60}")
    print(f" {title}")
    print(f"{'='*60}")

def verify_dataset():
    print_separator("ë°ì´í„°ì…‹ ë¡œë“œ ë° ê²€ì¦ ì‹œì‘")
    
    try:
        ds = easy_load(DEFAULT_INPUT_DIR,format="duplex")

        total_len = len(ds)
        if NUM_SAMPLES_TO_CHECK is not None and NUM_SAMPLES_TO_CHECK < total_len:
            print(f"âœ‚ï¸  ì„¤ì •ì— ë”°ë¼ ì•ë¶€ë¶„ {NUM_SAMPLES_TO_CHECK}ê°œë§Œ ì˜ë¼ì„œ ê²€ì¦í•©ë‹ˆë‹¤.")
            ds = ds.select(range(NUM_SAMPLES_TO_CHECK))
        print(f"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì„±ê³µ! ì´ ìƒ˜í”Œ ìˆ˜: {len(ds)}")
    except Exception as e:
        print(f"âŒ ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
# í†µê³„ ë³€ìˆ˜
    stats = {
        "max_seq_len": 0,
        "min_seq_len": 999999,
        "total_tokens": 0,
        "over_40k_count": 0,
        "short_target_audio_count": 0, 
        "zero_embedding_count": 0,
        "sr_mismatch_count": 0,
        "structure_error_count": 0,
    }

    # ìƒìˆ˜ ì„¤ì •
    AUDIO_TOKEN = -100
    SILENCE_TOKEN = 151643
    AUDIO_RATIO = 4
    TEXT_SLICE = 2
    
    inspected_target_structure = False

    # 2. ì „ì²´ ë°ì´í„° ìˆœíšŒ
    for i, sample in enumerate(tqdm(ds, desc="ê²€ì¦ ì§„í–‰ ì¤‘")):
        
        row = sample["dataset_row_obj"]

        # ---------------------------------------------------------------------
        # [ê¸°ëŠ¥ ì¶”ê°€] í† í° ìˆ˜ ì¹´ìš´íŠ¸ ë° í†µê³„
        # ---------------------------------------------------------------------
        seq_len = len(row.input_sequence)
        stats["max_seq_len"] = max(stats["max_seq_len"], seq_len)
        stats["min_seq_len"] = min(stats["min_seq_len"], seq_len)
        stats["total_tokens"] += seq_len
        
        # 1. ê¸¸ì´ 4ë§Œ í† í° ì²´í¬
        if seq_len > 40000:
            stats["over_40k_count"] += 1
            if stats["over_40k_count"] == 1:
                print(f"\nâŒ [Sample {i}] ê¸¸ì´ ì´ˆê³¼ ë°œê²¬: {seq_len} tokens")

        # 2. Target Audio 1ì´ˆ ì´í•˜ ì²´í¬
        for audio_seg in row.target_audios:
            duration = len(audio_seg.audio.waveform) / 24000.0
            if duration < 1.0:
                stats["short_target_audio_count"] += 1

        # 3. ìƒ˜í”Œë§ ë ˆì´íŠ¸ ì²´í¬
        if row.input_audios and row.input_audios[0].sampling_rate != 16000:
            stats["sr_mismatch_count"] += 1
        
        if row.target_audios and row.target_audios[0].audio.sampling_rate != 24000:
            stats["sr_mismatch_count"] += 1

        # 5. Speaker Embedding ì²´í¬
        # (ìµœì´ˆ 1íšŒë§Œ ê²½ê³  ì¶œë ¥, ë‚˜ë¨¸ì§€ëŠ” ì¹´ìš´íŠ¸ë§Œ í•¨)
        emb = np.array(row.speaker_embedding)
        if np.all(emb == 0):
            stats["zero_embedding_count"] += 1
            if stats["zero_embedding_count"] == 1:
                print(f"\nâŒ [Sample {i}] Speaker Embeddingì´ ëª¨ë‘ 0ì…ë‹ˆë‹¤. (ì´í›„ ìƒëµ)")

        # 6. êµ¬ì¡° íŒ¨í„´ ì²´í¬ (Silence 1ê°œ, Text 2ê°œ ë™ì  ëŒ€ì‘)
        try:
            try:
                first_audio_idx = row.input_sequence.index(AUDIO_TOKEN)
            except ValueError:
                # ì˜¤ë””ì˜¤ê°€ ì—†ëŠ” ê²½ìš°
                continue

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í™•ì¸
            if len(row.input_sequence[:first_audio_idx]) == 0:
                if stats["structure_error_count"] == 0:
                    print(f"\nâŒ [Sample {i}] ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ëˆ„ë½")
                stats["structure_error_count"] += 1
            
            # ë³¸ë¬¸ íŒ¨í„´ í™•ì¸
            body_seq = row.input_sequence[first_audio_idx:]
            cursor = 0
            
            while cursor < len(body_seq):
                # (A) ì˜¤ë””ì˜¤ 4ê°œ í™•ì¸
                audio_part = body_seq[cursor : cursor + AUDIO_RATIO]
                if len(audio_part) < AUDIO_RATIO: break 

                if not all(t == AUDIO_TOKEN for t in audio_part):
                    if stats["structure_error_count"] == 0:
                        print(f"\nâŒ [Sample {i}] ì˜¤ë””ì˜¤ íŒ¨í„´ ê¹¨ì§: {audio_part}")
                    stats["structure_error_count"] += 1
                    break
                
                cursor += AUDIO_RATIO 

                # (B) í…ìŠ¤íŠ¸/ì¹¨ë¬µ í™•ì¸
                if cursor >= len(body_seq): break
                first_token = body_seq[cursor]

                if first_token == SILENCE_TOKEN:
                    cursor += 1 # ì¹¨ë¬µì€ 1ê°œ
                else:
                    # í…ìŠ¤íŠ¸ëŠ” 2ê°œ (ì˜¤ë””ì˜¤ í† í° ë¼ì–´ìˆìœ¼ë©´ ì—ëŸ¬)
                    text_part = body_seq[cursor : cursor + TEXT_SLICE]
                    if len(text_part) < TEXT_SLICE: break 
                    if any(t == AUDIO_TOKEN for t in text_part):
                        if stats["structure_error_count"] == 0:
                            print(f"\nâŒ [Sample {i}] í…ìŠ¤íŠ¸ íŒ¨í„´ ê¹¨ì§: {text_part}")
                        stats["structure_error_count"] += 1
                        break
                    cursor += TEXT_SLICE 

        except Exception as e:
            if stats["structure_error_count"] == 0:
                print(f"\nâŒ [Sample {i}] ê²€ì¦ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            stats["structure_error_count"] += 1

    # ---------------------------------------------------------------------
    # ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
    # ---------------------------------------------------------------------
    avg_len = stats["total_tokens"] / len(ds) if len(ds) > 0 else 0
    
    print_separator("ğŸ“Š í† í° ê¸¸ì´ í†µê³„")
    print(f"â–¶ ìµœì†Œ ê¸¸ì´: {stats['min_seq_len']} tokens")
    print(f"â–¶ ìµœëŒ€ ê¸¸ì´: {stats['max_seq_len']} tokens (Limit: 40000)")
    print(f"â–¶ í‰ê·  ê¸¸ì´: {avg_len:.2f} tokens")

    print_separator("ğŸ›  ê²€ì¦ ê²°ê³¼ ìš”ì•½")
    print(f"1. 4ë§Œ í† í° ì´ˆê³¼ ìƒ˜í”Œ ìˆ˜ : {stats['over_40k_count']} ê°œ")
    print(f"2. êµ¬ì¡° íŒ¨í„´ ì—ëŸ¬ ìƒ˜í”Œ ìˆ˜ : {stats['structure_error_count']} ê°œ")
    print(f"3. SR ë¶ˆì¼ì¹˜ ìƒ˜í”Œ ìˆ˜    : {stats['sr_mismatch_count']} ê°œ")
    print(f"4. 1ì´ˆ ë¯¸ë§Œ ì˜¤ë””ì˜¤ ê°œìˆ˜  : {stats['short_target_audio_count']} ê°œ (ì°¸ê³ ìš©)")
    
    # ì„ë² ë”© ê²°ê³¼ í™•ì¸
    emb_status = "âœ… ì •ìƒ"
    if stats['zero_embedding_count'] > 0:
        emb_status = f"âŒ ì‹¤íŒ¨ ({stats['zero_embedding_count']} / {len(ds)} ìƒ˜í”Œì´ 0ìœ¼ë¡œ ì±„ì›Œì§)"
    print(f"5. Speaker Embedding    : {emb_status}")

    # ìµœì¢… íŒì •
    if (stats['over_40k_count'] == 0 and 
        stats['sr_mismatch_count'] == 0 and 
        stats['structure_error_count'] == 0):
        print("\nğŸ‰ [SUCCESS] ë°ì´í„°ì…‹ êµ¬ì¡° ê²€ì¦ í†µê³¼!")
    else:
        print("\nğŸ”¥ [FAILURE] ë°ì´í„°ì…‹ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìš”ì•½ì„ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    verify_dataset()