{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T11:06:42.342199Z",
     "start_time": "2025-11-21T11:06:42.331720Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from audio_processing import get_vad_slices\n",
    "from models.audio import SlicedAudioFile\n",
    "from models.events import ComedySession\n",
    "from utils import get_sliced_audio_base64\n",
    "\n",
    "dotenv.load_dotenv(dotenv_path=dotenv.find_dotenv())\n",
    "\n",
    "DATASET_DIR = Path(\"./dataset\").absolute()\n",
    "SLICE_CACHE = DATASET_DIR / \"slice_cache.jsonl\"\n",
    "AUDIO_DIR = (DATASET_DIR / \"audio_outputs\").absolute()\n",
    "audio_files = list(AUDIO_DIR.glob('*.flac'))\n",
    "\n",
    "print(f'Found {len(audio_files)} audio files in {AUDIO_DIR}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31 audio files in /Users/riverfog7/Workspace/SCA/data_prep/dataset/audio_outputs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riverfog7/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T10:50:01.014997Z",
     "start_time": "2025-11-21T10:50:01.009874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_list: List[SlicedAudioFile] = []\n",
    "\n",
    "if not SLICE_CACHE.exists():\n",
    "    for audio_path in tqdm(audio_files):\n",
    "        tqdm.write(f'Processing {audio_path.name}...')\n",
    "        file_list.append(get_vad_slices(audio_path, slice_min=2))\n",
    "\n",
    "    with open(SLICE_CACHE, 'w') as f:\n",
    "        for file in file_list:\n",
    "            f.write(file.model_dump_json() + '\\n')\n",
    "\n",
    "with open(SLICE_CACHE, 'r') as f:\n",
    "    for line in f:\n",
    "        file_list.append(SlicedAudioFile.model_validate_json(line))\n",
    "\n",
    "chunk_lst = [slice for file in file_list for slice in file.slices]\n",
    "print(f\"Total {sum(len(file.slices) for file in file_list)} slices found in {len(file_list)} audio files.\")"
   ],
   "id": "6913355cd154977d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 660 slices found in 31 audio files.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T11:00:15.191060Z",
     "start_time": "2025-11-21T11:00:15.185432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"You are an advanced audio analysis AI specializing in Standup Comedy transcription.\n",
    "Your task is to listen to the audio and generate a high-precision JSON timeline according to this schema:\n",
    "{schema}\n",
    "\n",
    "### CRITICAL TRANSCRIPTION PROTOCOLS:\n",
    "\n",
    "1. **CONTEXT & SEGMENTATION (Chunk Processing):**\n",
    "   - **Partial Input:** The provided audio is a specific **chunk** sliced from a longer performance. It is NOT the full video.\n",
    "   - **Boundary Handling:** Do not hallucinate words that might be cut off at the very start or very end of the file. Transcribe exactly what is audible within this slice.\n",
    "   - **Scope:** Your timeline must strictly reflect events occurring within this specific audio segment.\n",
    "\n",
    "2. **SOURCE SEPARATION (Comedian vs. Audience vs. Environment):**\n",
    "   - You must acoustically distinguish between the three distinct sound sources defined in the schema:\n",
    "   - **ComedianEvent:** Speech, breathing, or self-laughter coming specifically from the microphone/performer.\n",
    "   - **AudienceEvent:** Strictly crowd reactions (cheering, applause, collective laughter, heckling).\n",
    "   - **EnvironmentEvent:** Non-human or background sounds (Music, technical noise, accidental noise).\n",
    "\n",
    "3. **TEMPORAL DYNAMICS (Overlaps):**\n",
    "   - **Allow Overlaps:** Real comedy is fluid. Audience laughter often begins *before* the comedian finishes their punchline.\n",
    "   - **Timestamp Accuracy:** Capture these overlaps precisely. Do not artificially force events to happen sequentially if they occur simultaneously.\n",
    "\n",
    "4. **CLASSIFICATION & 'OTHER' HANDLING:**\n",
    "   - **Strict Categorization:** Attempt to categorize sounds using the specific Enums provided in the schema (e.g., 'laughter', 'applause', 'mic_feedback').\n",
    "   - **The 'Other' Fallback:** If a sound occurs that does not strictly fit the provided categories, you MUST select the **'other'** option for the `type` or `category` field.\n",
    "   - **Self-Explanation:** When you select **'other'**, you must explicitly describe the sound in the `content` field.\n",
    "     - *Example:* If a baby cries in the crowd (and 'crying' isn't an option), set `reaction_type='other'` and `content='[baby crying]'`.\n",
    "     - *Example:* If a chair squeaks on stage (and 'squeak' isn't an option), set `event_type='other'` and `content='[chair squeak]'`.\n",
    "   - **Speech Content:** For standard speech, transcribe verbatim.\n",
    "\"\"\"),\n",
    "    ('user', [\n",
    "        {\"type\": \"audio_url\", \"audio_url\": {\"url\": \"data:audio/wav;base64,{audio_base64}\"}},\n",
    "        {\"type\": \"text\", \"text\": \"Please transcribe this audio chunk and extract the relevant information according to the schema. This chunk belongs to the video: {video_id}. The chunk duration is {duration} seconds.\"},\n",
    "    ]),\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    api_key=\"EMPTY\",\n",
    "    model=os.getenv('VLLM_MODEL'),\n",
    "    base_url=os.getenv('VLLM_URL'),\n",
    "    max_tokens=8192,\n",
    "    # extra_body={\n",
    "    #     \"structured_outputs\": {\"json\": ImageAnalysis.model_json_schema()}\n",
    "    # },\n",
    ").with_structured_output(ComedySession).with_retry()\n",
    "\n",
    "chain = template | model"
   ],
   "id": "60ad3289078204eb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T11:01:05.062967Z",
     "start_time": "2025-11-21T11:00:15.562804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chunk_try = chunk_lst[1]\n",
    "chain.invoke({\n",
    "    \"audio_base64\": get_sliced_audio_base64(AUDIO_DIR, chunk_try),\n",
    "    \"video_id\": chunk_try.file,\n",
    "    \"schema\": ComedySession.model_json_schema(),\n",
    "    \"duration\": chunk_try.duration,\n",
    "})"
   ],
   "id": "2cb72aa8dbfd56ff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ComedySession(video_id='Judge Me If You Can! Ep01 ft. @ComicKaustubhAgarwal & @yuvrajdua4094.flac', timeline=[AudienceEvent(start=0.0, end=0.8, role='audience', content='Audience laughing', reaction_type='laughter'), ComedianEvent(start=0.8, end=5.0, role='comedian', content='Isse lal patth ka pata hai na? Chali to karaya. Bilkul hai.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=5.0, end=7.5, role='comedian', content='Lal patth wale isko bolte hain ki aapke full body mein do mahine lage hain, bhai.', event_type='speech', delivery_tag='energetic'), AudienceEvent(start=7.5, end=9.5, role='audience', content='Audience laughing', reaction_type='laughter'), ComedianEvent(start=9.5, end=13.9, role='comedian', content='Kya hum contestant ko bulane se pehle hi pooch len? Inlo ka stake pe kya laga hua hai?', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=13.9, end=16.1, role='comedian', content='Woh bada bura laga raha kartehu, lekin yeh perfume mein hai.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=16.1, end=16.6, role='comedian', content='Okay.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=16.6, end=17.3, role='comedian', content='Haan.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=17.3, end=20.6, role='comedian', content='To agar 50,000 woh jeeta to aap apna hi perfume de dooge?', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=20.6, end=21.4, role='comedian', content='Perfume de do?', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=21.4, end=24.0, role='comedian', content='But jaise main aapse do teen baar mila hua hoon, agar aapke paas yeh tha...', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=24.0, end=24.5, role='comedian', content='Haan.', event_type='speech', delivery_tag='energetic'), AudienceEvent(start=24.5, end=29.8, role='audience', content='Audience laughing', reaction_type='laughter'), ComedianEvent(start=29.8, end=30.4, role='comedian', content='Thik hai, kaustubh aapka stake pe kya hai?', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=30.4, end=32.4, role='comedian', content='Main ek laaya hoon, dekho, jo mujhe mila hai...', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=32.4, end=33.0, role='comedian', content='Hmm.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=33.0, end=35.1, role='comedian', content='A, woh hai mera bada keemti...', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=35.1, end=37.8, role='comedian', content='Bhai, ek mere dost ke earphones hain.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=37.8, end=38.3, role='comedian', content='Oh.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=38.3, end=41.3, role='comedian', content='Naina, yeh mujhe bahut pasand aaye the, lekin usko pata nahi hai maine mera paas hain.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=41.3, end=42.1, role='comedian', content='Acha.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=42.1, end=43.3, role='comedian', content=\"It's very important to me.\", event_type='speech', delivery_tag='energetic'), ComedianEvent(start=43.3, end=45.0, role='comedian', content='Iska stake thodi wahi hai, naina?', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=45.0, end=45.6, role='comedian', content='Naina?', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=45.6, end=46.3, role='comedian', content='Nahi, ek main rakh raha hoon.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=46.3, end=48.6, role='comedian', content='Par tujhe pata hai, chori ke definition kya hoti hai?', event_type='speech', delivery_tag='energetic'), AudienceEvent(start=48.6, end=50.1, role='audience', content='Audience laughing', reaction_type='laughter'), ComedianEvent(start=50.1, end=51.1, role='comedian', content='Cool hai, a.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=51.1, end=53.8, role='comedian', content='Hum log ready hain contestant ke liye.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=53.8, end=58.2, role='comedian', content='Main bata deta hoon ki is contestant ke baare mein hume pehle se kuch bhi nahi pata hai.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=58.2, end=61.3, role='comedian', content='Zero idea at all. Nahi yeh pata hai ki purush hai, mahila hai, kya inki jaankari hai, nothing at all.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=61.3, end=66.0, role='comedian', content='We have to judge this person totally in front of you, to tum log bhi barabar idea hai ki kon aa raha hai aur hume barabar idea hai.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=66.0, end=68.6, role='comedian', content='Meri team ne unhe chuna hai, meri team peeche baithi hui hai aur...', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=68.6, end=71.2, role='comedian', content='Toh inhone mere ko info diya jo main aapke samne pad raha hoon. Jo first contestant hai, unki info yeh hai ki unka naam hai Ananya Yadav.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=71.2, end=73.0, role='comedian', content='Ananya, 22 saal ki hain, a...', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=73.0, end=77.9, role='comedian', content='Yeh do brand aur ek company ke liye freelance content ka kaam karti hain. Already no respect.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=77.9, end=78.2, role='comedian', content='Okay.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=78.2, end=79.4, role='comedian', content='Also unemployed.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=79.4, end=80.1, role='comedian', content='Toh...', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=80.1, end=82.8, role='comedian', content='Ab kuch random facts inke baare mein. Is ladki ko check bharte hue anxiety hoti hai.', event_type='speech', delivery_tag='energetic'), AudienceEvent(start=82.8, end=84.3, role='audience', content='Audience laughing', reaction_type='laughter'), ComedianEvent(start=84.3, end=88.7, role='comedian', content='A, inko words ke spellings aur logon ke naam bilkul yaad nahi rehte hain, okay.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=88.7, end=89.2, role='comedian', content='Okay.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=89.2, end=89.8, role='comedian', content='Tadka dena...', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=89.8, end=90.2, role='comedian', content='Hmm.', event_type='speech', delivery_tag='energetic'), AudienceEvent(start=90.2, end=93.1, role='audience', content='Audience laughing', reaction_type='laughter'), ComedianEvent(start=93.1, end=97.4, role='comedian', content='Yeh show ki winning amount se apne parents ke liye kuch super cute karegi.', event_type='speech', delivery_tag='energetic'), ComedianEvent(start=97.4, end=98.4, role='comedian', content=\"Oh, that's so sweet.\", event_type='speech', delivery_tag='energetic'), ComedianEvent(start=98.4, end=101.2, role='comedian', content='Bhaiya budget dekh rahe ho, KBC mein hota hai ghar kharidh lenge.', event_type='speech', delivery_tag='energetic'), AudienceEvent(start=101.2, end=103.2, role='audience', content='Audience laughing', reaction_type='laughter'), ComedianEvent(start=103.2, end=105.5, role='comedian', content='Yahan pe kuch super cute...', event_type='speech', delivery_tag='energetic'), AudienceEvent(start=105.5, end=108.1, role='audience', content='Audience laughing', reaction_type='laughter')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T12:56:14.917203Z",
     "start_time": "2025-11-21T11:07:08.373824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "OUTPUT_FILE = DATASET_DIR / \"inference_results.jsonl\"\n",
    "file_lock = threading.Lock()\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    pass\n",
    "def process_and_save_chunk(chunk):\n",
    "    try:\n",
    "        inference_result = chain.invoke({\n",
    "            \"audio_base64\": get_sliced_audio_base64(AUDIO_DIR, chunk),\n",
    "            \"video_id\": \"placeholder\",\n",
    "            \"schema\": ComedySession.model_json_schema(),\n",
    "            \"duration\": chunk.duration,\n",
    "        })\n",
    "        chunk_data = chunk.model_dump() if hasattr(chunk, 'model_dump') else vars(chunk)\n",
    "\n",
    "        combined_record = {\n",
    "            \"chunk_metadata\": chunk_data,\n",
    "            \"inference\": inference_result.model_dump()\n",
    "        }\n",
    "\n",
    "        with file_lock:\n",
    "            with open(OUTPUT_FILE, 'a') as f:\n",
    "                f.write(json.dumps(combined_record) + \"\\n\")\n",
    "        return combined_record\n",
    "\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed on chunk {chunk}: {str(e)}\")\n",
    "\n",
    "results = []\n",
    "num_workers = 32\n",
    "\n",
    "print(f\"Starting processing with {num_workers} workers. Saving to {OUTPUT_FILE}...\")\n",
    "with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "    future_to_chunk = {\n",
    "        executor.submit(process_and_save_chunk, chunk): chunk\n",
    "        for chunk in chunk_lst\n",
    "    }\n",
    "\n",
    "    for future in tqdm(as_completed(future_to_chunk), total=len(chunk_lst)):\n",
    "        chunk = future_to_chunk[future]\n",
    "        try:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "        except Exception as exc:\n",
    "            tqdm.write(f\"Error processing {chunk.file} [{chunk.start}-{chunk.end}]: {exc}\")\n",
    "\n",
    "print(f\"\\nProcessing complete. {len(results)} chunks successfully processed.\")"
   ],
   "id": "fde163a238337120",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing with 32 workers. Saving to /Users/riverfog7/Workspace/SCA/data_prep/dataset/inference_results.jsonl...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 297/660 [49:55<1:01:01, 10.09s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AudioSlice' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mLengthFinishReasonError\u001B[39m                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 7\u001B[39m, in \u001B[36mprocess_and_save_chunk\u001B[39m\u001B[34m(chunk)\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m     inference_result = \u001B[43mchain\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43maudio_base64\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mget_sliced_audio_base64\u001B[49m\u001B[43m(\u001B[49m\u001B[43mAUDIO_DIR\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvideo_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mplaceholder\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mschema\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mComedySession\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_json_schema\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m        \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mduration\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mduration\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     13\u001B[39m     chunk_data = chunk.model_dump() \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(chunk, \u001B[33m'\u001B[39m\u001B[33mmodel_dump\u001B[39m\u001B[33m'\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mvars\u001B[39m(chunk)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3129\u001B[39m, in \u001B[36mRunnableSequence.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3128\u001B[39m             \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3129\u001B[39m                 input_ = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3130\u001B[39m \u001B[38;5;66;03m# finish the root run\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/retry.py:201\u001B[39m, in \u001B[36mRunnableRetry.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m    197\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m    198\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m    199\u001B[39m     \u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Input, config: RunnableConfig | \u001B[38;5;28;01mNone\u001B[39;00m = \u001B[38;5;28;01mNone\u001B[39;00m, **kwargs: Any\n\u001B[32m    200\u001B[39m ) -> Output:\n\u001B[32m--> \u001B[39m\u001B[32m201\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_with_config\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_invoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:2050\u001B[39m, in \u001B[36mRunnable._call_with_config\u001B[39m\u001B[34m(self, func, input_, config, run_type, serialized, **kwargs)\u001B[39m\n\u001B[32m   2047\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m set_config_context(child_config) \u001B[38;5;28;01mas\u001B[39;00m context:\n\u001B[32m   2048\u001B[39m         output = cast(\n\u001B[32m   2049\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mOutput\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m-> \u001B[39m\u001B[32m2050\u001B[39m             \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2051\u001B[39m \u001B[43m                \u001B[49m\u001B[43mcall_func_with_variable_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m   2052\u001B[39m \u001B[43m                \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2053\u001B[39m \u001B[43m                \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2054\u001B[39m \u001B[43m                \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2055\u001B[39m \u001B[43m                \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2056\u001B[39m \u001B[43m                \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2057\u001B[39m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[32m   2058\u001B[39m         )\n\u001B[32m   2059\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/config.py:428\u001B[39m, in \u001B[36mcall_func_with_variable_args\u001B[39m\u001B[34m(func, input, config, run_manager, **kwargs)\u001B[39m\n\u001B[32m    427\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m] = run_manager\n\u001B[32m--> \u001B[39m\u001B[32m428\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/retry.py:186\u001B[39m, in \u001B[36mRunnableRetry._invoke\u001B[39m\u001B[34m(self, input_, run_manager, config, **kwargs)\u001B[39m\n\u001B[32m    179\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_invoke\u001B[39m(\n\u001B[32m    180\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    181\u001B[39m     input_: Input,\n\u001B[32m   (...)\u001B[39m\u001B[32m    184\u001B[39m     **kwargs: Any,\n\u001B[32m    185\u001B[39m ) -> Output:\n\u001B[32m--> \u001B[39m\u001B[32m186\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_sync_retrying\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreraise\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    187\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mwith\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m:\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:445\u001B[39m, in \u001B[36mBaseRetrying.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    444\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m445\u001B[39m     do = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43miter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m=\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    446\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(do, DoAttempt):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:378\u001B[39m, in \u001B[36mBaseRetrying.iter\u001B[39m\u001B[34m(self, retry_state)\u001B[39m\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m action \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.iter_state.actions:\n\u001B[32m--> \u001B[39m\u001B[32m378\u001B[39m     result = \u001B[43maction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:420\u001B[39m, in \u001B[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001B[39m\u001B[34m(rs)\u001B[39m\n\u001B[32m    419\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.reraise:\n\u001B[32m--> \u001B[39m\u001B[32m420\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43mretry_exc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    421\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m retry_exc \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mfut\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexception\u001B[39;00m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/tenacity/__init__.py:187\u001B[39m, in \u001B[36mRetryError.reraise\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    186\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.last_attempt.failed:\n\u001B[32m--> \u001B[39m\u001B[32m187\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlast_attempt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    188\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    400\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m     \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/retry.py:188\u001B[39m, in \u001B[36mRunnableRetry._invoke\u001B[39m\u001B[34m(self, input_, run_manager, config, **kwargs)\u001B[39m\n\u001B[32m    187\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m attempt:\n\u001B[32m--> \u001B[39m\u001B[32m188\u001B[39m     result = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    189\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    190\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_patch_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattempt\u001B[49m\u001B[43m.\u001B[49m\u001B[43mretry_state\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    191\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    192\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    193\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m attempt.retry_state.outcome \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m attempt.retry_state.outcome.failed:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5534\u001B[39m, in \u001B[36mRunnableBindingBase.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5527\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5528\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m   5529\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5532\u001B[39m     **kwargs: Any | \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   5533\u001B[39m ) -> Output:\n\u001B[32m-> \u001B[39m\u001B[32m5534\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbound\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   5535\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   5536\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5537\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5538\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:3127\u001B[39m, in \u001B[36mRunnableSequence.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   3126\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m i == \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m3127\u001B[39m     input_ = \u001B[43mcontext\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstep\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3128\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/runnables/base.py:5534\u001B[39m, in \u001B[36mRunnableBindingBase.invoke\u001B[39m\u001B[34m(self, input, config, **kwargs)\u001B[39m\n\u001B[32m   5527\u001B[39m \u001B[38;5;129m@override\u001B[39m\n\u001B[32m   5528\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minvoke\u001B[39m(\n\u001B[32m   5529\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m   5532\u001B[39m     **kwargs: Any | \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m   5533\u001B[39m ) -> Output:\n\u001B[32m-> \u001B[39m\u001B[32m5534\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbound\u001B[49m\u001B[43m.\u001B[49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   5535\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m   5536\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5537\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43m{\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   5538\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:385\u001B[39m, in \u001B[36mBaseChatModel.invoke\u001B[39m\u001B[34m(self, input, config, stop, **kwargs)\u001B[39m\n\u001B[32m    380\u001B[39m config = ensure_config(config)\n\u001B[32m    381\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m cast(\n\u001B[32m    382\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mAIMessage\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    383\u001B[39m     cast(\n\u001B[32m    384\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mChatGeneration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m--> \u001B[39m\u001B[32m385\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate_prompt\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    386\u001B[39m \u001B[43m            \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_convert_input\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    388\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcallbacks\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    389\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtags\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mtags\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[43m            \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmetadata\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    391\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_name\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    392\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpop\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrun_id\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    393\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    394\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m.generations[\u001B[32m0\u001B[39m][\u001B[32m0\u001B[39m],\n\u001B[32m    395\u001B[39m     ).message,\n\u001B[32m    396\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1104\u001B[39m, in \u001B[36mBaseChatModel.generate_prompt\u001B[39m\u001B[34m(self, prompts, stop, callbacks, **kwargs)\u001B[39m\n\u001B[32m   1103\u001B[39m prompt_messages = [p.to_messages() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m prompts]\n\u001B[32m-> \u001B[39m\u001B[32m1104\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt_messages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:914\u001B[39m, in \u001B[36mBaseChatModel.generate\u001B[39m\u001B[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001B[39m\n\u001B[32m    912\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    913\u001B[39m     results.append(\n\u001B[32m--> \u001B[39m\u001B[32m914\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    915\u001B[39m \u001B[43m            \u001B[49m\u001B[43mm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    916\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    917\u001B[39m \u001B[43m            \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrun_managers\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m    918\u001B[39m \u001B[43m            \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    919\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    920\u001B[39m     )\n\u001B[32m    921\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1208\u001B[39m, in \u001B[36mBaseChatModel._generate_with_cache\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1207\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m inspect.signature(\u001B[38;5;28mself\u001B[39m._generate).parameters.get(\u001B[33m\"\u001B[39m\u001B[33mrun_manager\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m-> \u001B[39m\u001B[32m1208\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_generate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1209\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrun_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1210\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1211\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1333\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1332\u001B[39m         e.response = raw_response.http_response  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1333\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[32m   1334\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m   1335\u001B[39m     \u001B[38;5;28mself\u001B[39m.include_response_headers\n\u001B[32m   1336\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m raw_response \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1337\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(raw_response, \u001B[33m\"\u001B[39m\u001B[33mheaders\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m   1338\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/langchain_openai/chat_models/base.py:1305\u001B[39m, in \u001B[36mBaseChatOpenAI._generate\u001B[39m\u001B[34m(self, messages, stop, run_manager, **kwargs)\u001B[39m\n\u001B[32m   1300\u001B[39m     raw_response = (\n\u001B[32m   1301\u001B[39m         \u001B[38;5;28mself\u001B[39m.root_client.chat.completions.with_raw_response.parse(\n\u001B[32m   1302\u001B[39m             **payload\n\u001B[32m   1303\u001B[39m         )\n\u001B[32m   1304\u001B[39m     )\n\u001B[32m-> \u001B[39m\u001B[32m1305\u001B[39m     response = \u001B[43mraw_response\u001B[49m\u001B[43m.\u001B[49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1306\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m openai.BadRequestError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/openai/_legacy_response.py:139\u001B[39m, in \u001B[36mLegacyAPIResponse.parse\u001B[39m\u001B[34m(self, to)\u001B[39m\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_given(\u001B[38;5;28mself\u001B[39m._options.post_parser):\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m     parsed = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_options\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpost_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparsed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    141\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(parsed, BaseModel):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:178\u001B[39m, in \u001B[36mCompletions.parse.<locals>.parser\u001B[39m\u001B[34m(raw_completion)\u001B[39m\n\u001B[32m    177\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mparser\u001B[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001B[32m--> \u001B[39m\u001B[32m178\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_parse_chat_completion\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    179\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresponse_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    180\u001B[39m \u001B[43m        \u001B[49m\u001B[43mchat_completion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mraw_completion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    181\u001B[39m \u001B[43m        \u001B[49m\u001B[43minput_tools\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchat_completion_tools\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    182\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/openai/lib/_parsing/_completions.py:100\u001B[39m, in \u001B[36mparse_chat_completion\u001B[39m\u001B[34m(response_format, input_tools, chat_completion)\u001B[39m\n\u001B[32m     99\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m choice.finish_reason == \u001B[33m\"\u001B[39m\u001B[33mlength\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m100\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m LengthFinishReasonError(completion=chat_completion)\n\u001B[32m    102\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m choice.finish_reason == \u001B[33m\"\u001B[39m\u001B[33mcontent_filter\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[31mLengthFinishReasonError\u001B[39m: Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=2915, total_tokens=11107, completion_tokens_details=None, prompt_tokens_details=None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 41\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m41\u001B[39m     result = \u001B[43mfuture\u001B[49m\u001B[43m.\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     42\u001B[39m     results.append(result)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:449\u001B[39m, in \u001B[36mFuture.result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    448\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._state == FINISHED:\n\u001B[32m--> \u001B[39m\u001B[32m449\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__get_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    451\u001B[39m \u001B[38;5;28mself\u001B[39m._condition.wait(timeout)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/_base.py:401\u001B[39m, in \u001B[36mFuture.__get_result\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    400\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m401\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._exception\n\u001B[32m    402\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    403\u001B[39m     \u001B[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/.local/share/uv/python/cpython-3.13.2-macos-aarch64-none/lib/python3.13/concurrent/futures/thread.py:59\u001B[39m, in \u001B[36m_WorkItem.run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m     result = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     60\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 26\u001B[39m, in \u001B[36mprocess_and_save_chunk\u001B[39m\u001B[34m(chunk)\u001B[39m\n\u001B[32m     25\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m---> \u001B[39m\u001B[32m26\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mFailed on chunk \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchunk\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mRuntimeError\u001B[39m: Failed on chunk start_time=0.0 end_time=118.94999999999999 file='2 Hours of All Killer Comedy ｜ Stand-Up Comedy Compilation.flac': Could not parse response content as the length limit was reached - CompletionUsage(completion_tokens=8192, prompt_tokens=2915, total_tokens=11107, completion_tokens_details=None, prompt_tokens_details=None)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 44\u001B[39m\n\u001B[32m     42\u001B[39m             results.append(result)\n\u001B[32m     43\u001B[39m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m---> \u001B[39m\u001B[32m44\u001B[39m             tqdm.write(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mError processing \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchunk.file\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mchunk.end\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m]: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexc\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     46\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[33mProcessing complete. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(results)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m chunks successfully processed.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Workspace/SCA/data_prep/.venv/lib/python3.13/site-packages/pydantic/main.py:1026\u001B[39m, in \u001B[36mBaseModel.__getattr__\u001B[39m\u001B[34m(self, item)\u001B[39m\n\u001B[32m   1023\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().\u001B[34m__getattribute__\u001B[39m(item)  \u001B[38;5;66;03m# Raises AttributeError if appropriate\u001B[39;00m\n\u001B[32m   1024\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1025\u001B[39m     \u001B[38;5;66;03m# this is the current error\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1026\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m object has no attribute \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mitem\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[33m'\u001B[39m)\n",
      "\u001B[31mAttributeError\u001B[39m: 'AudioSlice' object has no attribute 'start'"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
